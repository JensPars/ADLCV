{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikriise/anaconda3/envs/DiffAug/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import copy\n",
    "from detectron2.structures import BitMasks, Boxes, Instances\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.data.transforms.augmentation_impl import RandomRotation\n",
    "from detectron2.structures import Boxes, ImageList, Instances, pairwise_iou, BoxMode\n",
    "from detectron2.evaluation.coco_evaluation import instances_to_coco_json\n",
    "import detectron2.utils.comm as comm\n",
    "from helpers import blend_image\n",
    "import math\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "def convert_instance_to_dict(x):\n",
    "    if \"instances\" not in x:\n",
    "        return x\n",
    "    inst = x[\"instances\"]\n",
    "    try:\n",
    "        result = {\n",
    "            \"img\": x[\"image\"].numpy(),\n",
    "            \"file_name\": x[\"file_name\"],\n",
    "            \"gt_bboxes\": inst.get(\"gt_boxes\").tensor.numpy(),\n",
    "            \"gt_labels\": inst.get(\"gt_classes\").numpy(),\n",
    "            \"gt_masks\": inst.get(\"gt_masks\").tensor.numpy(),\n",
    "        }\n",
    "        return result\n",
    "    except:\n",
    "        print(\"error in convert\")\n",
    "        return None\n",
    "\n",
    "\n",
    "class CopyPaste:\n",
    "    \"\"\"Simple Copy-Paste is a Strong Data Augmentation Method for Instance\n",
    "    Segmentation The simple copy-paste transform steps are as follows:\n",
    "    1. The destination image is already resized with aspect ratio kept,\n",
    "       cropped and padded.\n",
    "    2. Randomly select a source image, which is also already resized\n",
    "       with aspect ratio kept, cropped and padded in a similar way\n",
    "       as the destination image.\n",
    "    3. Randomly select some objects from the source image.\n",
    "    4. Paste these source objects to the destination image directly,\n",
    "       due to the source and destination image have the same size.\n",
    "    5. Update object masks of the destination image, for some origin objects\n",
    "       may be occluded.\n",
    "    6. Generate bboxes from the updated destination masks and\n",
    "       filter some objects which are totally occluded, and adjust bboxes\n",
    "       which are partly occluded.\n",
    "    7. Append selected source bboxes, masks, and labels.\n",
    "    Args:\n",
    "        max_num_pasted (int): The maximum number of pasted objects.\n",
    "            Default: 100.\n",
    "        bbox_occluded_thr (int): The threshold of occluded bbox.\n",
    "            Default: 10.\n",
    "        mask_occluded_thr (int): The threshold of occluded mask.\n",
    "            Default: 300.\n",
    "        selected (bool): Whether select objects or not. If select is False,\n",
    "            all objects of the source image will be pasted to the\n",
    "            destination image.\n",
    "            Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_num_pasted=100,\n",
    "        bbox_occluded_thr=10,\n",
    "        mask_occluded_thr=300,\n",
    "        selected=True,\n",
    "        dataset=None,\n",
    "        repeat_probs=None,\n",
    "        blank_ratio=-1,\n",
    "        rotate_ang=30,\n",
    "        cid_filter=[],\n",
    "        limit_inp_trans=False,\n",
    "        rotate_src=False,\n",
    "        cp_method=\"basic\",\n",
    "    ):\n",
    "        self.max_num_pasted = max_num_pasted\n",
    "        self.bbox_occluded_thr = bbox_occluded_thr\n",
    "        self.mask_occluded_thr = mask_occluded_thr\n",
    "        self.selected = selected\n",
    "        self.dataset = dataset\n",
    "        self.repeat_probs = repeat_probs\n",
    "        self.blank_ratio = blank_ratio\n",
    "        self.cid_filter = cid_filter\n",
    "        self.cp_method = cp_method\n",
    "        self.rotate_aug = RandomRotation([-rotate_ang, rotate_ang])\n",
    "        self.count = 0\n",
    "        self.limit_inp_trans = limit_inp_trans\n",
    "        self.rotate_src = rotate_src\n",
    "\n",
    "    def get_indexes(self, dataset):\n",
    "        \"\"\"Call function to collect indexes.s.\n",
    "        Args:\n",
    "            dataset (:obj:`MultiImageMixDataset`): The dataset.\n",
    "        Returns:\n",
    "            list: Indexes.\n",
    "        \"\"\"\n",
    "        if self.repeat_probs is not None:\n",
    "            assert len(self.repeat_probs) == len(dataset)\n",
    "            # return random.choices(list(range(dataset)), weight=self.repeat_probs)\n",
    "            return random.choice(list(range(len(dataset))), p=self.repeat_probs)\n",
    "        return random.randint(0, len(dataset))\n",
    "\n",
    "    def remove_background(self, results):\n",
    "        img = results[\"image\"]\n",
    "        gt_masks = results[\"instances\"].gt_masks.tensor\n",
    "        # np.where(np.any(src_masks, axis=0), 1, 0)\n",
    "        # compose_mask = torch.where(torch.any(gt_masks, dim=0), 1, 0, dtype=img.dtype)\n",
    "        compose_mask = torch.any(gt_masks, dim=0).type(img.dtype)\n",
    "        img_fg = img * compose_mask[None]\n",
    "        results[\"image\"] = img_fg\n",
    "        return results\n",
    "\n",
    "    def _inp_rotate(self, results, inp=True):\n",
    "        # img_inp = results['inp_image'].numpy().transpose(1,2,0) # np (h,w,3)\n",
    "        # img_inp = img_inp.numpy().transpose(1,2,0)\n",
    "        image = results[\"image\"].numpy().transpose(1, 2, 0)\n",
    "\n",
    "        inst = results[\"instances\"]\n",
    "        if len(inst) == 0:\n",
    "            return results\n",
    "        gt_cls = inst.get(\"gt_classes\").tolist()\n",
    "        cls_filter = torch.tensor([(x in self.cid_filter) for x in gt_cls])\n",
    "        inst_filter = inst[cls_filter]\n",
    "        if len(inst_filter) == 0:\n",
    "            return results\n",
    "        masks = inst_filter.get(\"gt_masks\").tensor.numpy()\n",
    "        masks_origin = masks\n",
    "        bboxes = self.get_bboxes(masks).astype(int)\n",
    "\n",
    "        def crop_from_img(bboxes, img, masks):\n",
    "            img_list = []\n",
    "            mask_list = []\n",
    "            for i, bbox in enumerate(bboxes):\n",
    "                img_list.append(img[bbox[1] : bbox[3], bbox[0] : bbox[2]])\n",
    "                mask_list.append(masks[i][bbox[1] : bbox[3], bbox[0] : bbox[2]])\n",
    "            return img_list, mask_list\n",
    "\n",
    "        def create_canvas(img, bboxes):\n",
    "            h, w = img.shape[:2]\n",
    "            max_h = bboxes[..., 1::2].max()\n",
    "            max_w = bboxes[..., 0::2].max()\n",
    "            h, w = max(h, max_h), max(w, max_w)\n",
    "            canvas = np.zeros((h, w, 3), dtype=img.dtype)\n",
    "            return canvas\n",
    "\n",
    "        def copy_on_img(dst_bbox, img):\n",
    "            dst_bbox_center = (dst_bbox[:2] + dst_bbox[2:]) // 2\n",
    "            src_bbox = np.array([0, 0, img.shape[1], img.shape[0]])\n",
    "            src_bbox_center = (src_bbox[:2] + src_bbox[2:]) // 2\n",
    "            shift = dst_bbox_center - src_bbox_center\n",
    "            src_bbox_new = src_bbox + np.concatenate([shift, shift])  # shift\n",
    "            # h, w = dst_img.shape[:2]\n",
    "            # dst_img[src_bbox_new[1]:src_bbox_new[3], src_bbox_new[0]:src_bbox_new[2]][mask] = img[mask]\n",
    "            return src_bbox_new\n",
    "\n",
    "        img_list, mask_list = crop_from_img(bboxes, image, masks)\n",
    "        # image_cp = img_inp.copy()\n",
    "        mask_new_list = []\n",
    "        bbox_new_list = []\n",
    "        img_r_list = []\n",
    "        mask_r_list = []\n",
    "        for bbox, mask, img in zip(bboxes, mask_list, img_list):\n",
    "\n",
    "            aug_input = T.AugInput(img, sem_seg=None)\n",
    "            transform = self.rotate_aug(aug_input)\n",
    "            img_r = aug_input.image\n",
    "            mask_r = transform.apply_image(mask.astype(np.uint8))\n",
    "            mask_r = mask_r.astype(bool)\n",
    "\n",
    "            bbox_new = copy_on_img(bbox, img_r)\n",
    "            bbox_new_list.append(bbox_new)\n",
    "            img_r_list.append(img_r)\n",
    "            mask_r_list.append(mask_r)\n",
    "            # mask_new_list.append(mask_new)\n",
    "\n",
    "        canvas = create_canvas(image, np.stack(bbox_new_list))\n",
    "        h_c, w_c = canvas.shape[:2]\n",
    "        for bbox_new, mask_r, img_r in zip(bbox_new_list, mask_r_list, img_r_list):\n",
    "            bbox_new = bbox_new.clip(min=0)\n",
    "            w, h = bbox_new[-2:] - bbox_new[:2]\n",
    "            mask_r = mask_r[-h:, -w:]\n",
    "            img_r = img_r[-h:, -w:]\n",
    "            canvas[bbox_new[1] : bbox_new[3], bbox_new[0] : bbox_new[2]][mask_r] = (\n",
    "                img_r[mask_r]\n",
    "            )\n",
    "            mask_new = np.zeros((h_c, w_c), dtype=bool)\n",
    "            mask_new[bbox_new[1] : bbox_new[3], bbox_new[0] : bbox_new[2]] = mask_r\n",
    "            mask_new_list.append(mask_new)\n",
    "\n",
    "        if self.limit_inp_trans:\n",
    "            h_o, w_o = image.shape[:2]\n",
    "            canvas = canvas[:h_o, :w_o]\n",
    "            for i, mask in enumerate(mask_new_list):\n",
    "                mask_new_list[i] = mask[:h_o, :w_o] & masks_origin[i][:h_o, :w_o]\n",
    "\n",
    "        # bboxes_new = np.stack(bbox_new_list)\n",
    "        mask_new = np.stack(mask_new_list)\n",
    "        bboxes_new = self.get_bboxes(mask_new)\n",
    "\n",
    "        results_origin = copy.deepcopy(results)\n",
    "        file_name = results[\"file_name\"]\n",
    "        results_origin[\"instances\"] = results_origin[\"instances\"][~cls_filter]\n",
    "        if inp and \"inp_image\" in results:\n",
    "            results_origin[\"image\"] = results.pop(\"inp_image\")\n",
    "        else:\n",
    "            results_origin[\"image\"] = results[\"image\"]\n",
    "\n",
    "        origin_dict = convert_instance_to_dict(results_origin)\n",
    "        # import cv2\n",
    "        # cv2.imwrite('inp_show/{}_inp-origin.jpg'.format(self.count), results['image'].numpy().transpose(1,2,0)[...,::-1])\n",
    "        # cv2.imwrite('inp_show/{}_inp-src.jpg'.format(self.count), origin_dict['img'].transpose(1,2,0)[...,::-1])\n",
    "        paste_dict = {\n",
    "            \"img\": canvas.transpose(2, 0, 1),\n",
    "            \"gt_bboxes\": bboxes_new,\n",
    "            \"gt_labels\": inst_filter.get(\"gt_classes\").numpy(),\n",
    "            \"gt_masks\": mask_new,\n",
    "        }\n",
    "        results, valid_idx, scale = self._scp_src_to_dst(origin_dict, paste_dict, True)\n",
    "        # cv2.imwrite('inp_show/{}_inp-rotate_raw.jpg'.format(self.count), paste_dict['img'].transpose(1,2,0)[...,::-1])\n",
    "        # cv2.imwrite('inp_show/{}_inp-rotate.jpg'.format(self.count), results['img'].transpose(1,2,0)[...,::-1])\n",
    "        # cv2.imwrite('inp_show/{}_np-rotate_mask.jpg'.format(self.count), mask_new.max(axis=0).astype(np.uint8)[...,None]* 255)\n",
    "        results_origin = {}\n",
    "        h, w = results[\"img\"].shape[-2:]\n",
    "        results_origin[\"file_name\"] = file_name\n",
    "        results_origin[\"image\"] = torch.from_numpy(results[\"img\"])\n",
    "        results_origin[\"instances\"] = Instances((h, w))\n",
    "        results_origin[\"instances\"].gt_boxes = Boxes(results[\"gt_bboxes\"])\n",
    "        results_origin[\"instances\"].gt_classes = torch.tensor(\n",
    "            results[\"gt_labels\"], dtype=torch.int64\n",
    "        )\n",
    "        results_origin[\"instances\"].gt_masks = BitMasks(results[\"gt_masks\"])\n",
    "        results_origin[\"height\"], results_origin[\"width\"] = h, w\n",
    "\n",
    "        if 0:\n",
    "            result = results_origin\n",
    "            from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "            img = result[\"image\"]\n",
    "            inst_pred = result[\"instances\"]\n",
    "            inst_pred.pred_boxes = inst_pred.gt_boxes\n",
    "            inst_pred.pred_classes = inst_pred.gt_classes\n",
    "            inst_pred.pred_masks = inst_pred.gt_masks\n",
    "            visualizer = Visualizer(img.permute(1, 2, 0), metadata=None)\n",
    "            vis = visualizer.overlay_instances(\n",
    "                boxes=inst_pred.gt_boxes,\n",
    "                labels=inst_pred.gt_classes.tolist(),\n",
    "                masks=inst_pred.gt_masks,\n",
    "            )\n",
    "            vis.save(\"inp_show/{}_show.jpg\".format(self.count))\n",
    "            self.count += 1\n",
    "\n",
    "        return results_origin\n",
    "\n",
    "    def __call__(self, results, logger=None, save_img_dir=None):\n",
    "        \"\"\"Call function to make a copy-paste of image.\n",
    "        Args:\n",
    "            results (dict): Result dict.\n",
    "        Returns:\n",
    "            dict: Result dict with copy-paste transformed.\n",
    "        \"\"\"\n",
    "\n",
    "        if \"inp_image\" in results:\n",
    "            if np.random.randint(0, 3):\n",
    "                return self._inp_rotate(results)\n",
    "        results_origin = copy.deepcopy(results)\n",
    "        assert \"mix_results\" in results\n",
    "        num_images = len(results[\"mix_results\"])\n",
    "        # when mix results is empty, jump scp\n",
    "        if num_images == 0:\n",
    "            results.pop(\"mix_results\")\n",
    "            return results\n",
    "        # assert num_images == 1, \\\n",
    "        #     f'CopyPaste only supports processing 2 images, got {num_images}'\n",
    "\n",
    "        def update_log_dict(x):\n",
    "            return {\n",
    "                \"file_name\": x[\"file_name\"],\n",
    "                \"labels\": x[\"gt_labels\"].tolist(),\n",
    "                \"boxes\": x[\"gt_bboxes\"].tolist(),\n",
    "            }\n",
    "\n",
    "        results = convert_instance_to_dict(results)\n",
    "        if results is None:\n",
    "            return results_origin\n",
    "        if logger is not None:\n",
    "            scp_log_dict = dict()\n",
    "            scp_log_dict[\"dst\"] = update_log_dict(results)\n",
    "            scp_log_dict[\"src\"] = []\n",
    "            # scp_log_dict.update(src_image=)\n",
    "        src_results = None\n",
    "        for i in range(num_images):\n",
    "            mix_results = results_origin[\"mix_results\"][i]\n",
    "            if self.rotate_src and np.random.randint(0, 3):\n",
    "                mix_results = self._inp_rotate(mix_results, False)\n",
    "            selected_results = convert_instance_to_dict(mix_results)\n",
    "            if selected_results is None:\n",
    "                continue\n",
    "            if self.selected:\n",
    "                selected_results = self._select_object(selected_results)\n",
    "\n",
    "            if len(selected_results[\"gt_bboxes\"]) == 0:\n",
    "                continue\n",
    "            if logger is not None:\n",
    "                scp_log_dict[\"src\"].append(update_log_dict(selected_results))\n",
    "\n",
    "            if src_results is None:\n",
    "                src_results = selected_results\n",
    "                continue\n",
    "\n",
    "            src_results = self._scp_src_to_dst(\n",
    "                src_results, selected_results, is_tmp_dst=True\n",
    "            )\n",
    "\n",
    "        if src_results is not None:\n",
    "            results, valid_idx, scale = self._scp_src_to_dst(results, src_results, True)\n",
    "            if logger is not None:\n",
    "                scp_log_dict[\"dst\"][\"valid_obj\"] = valid_idx.tolist()\n",
    "                scp_log_dict[\"scale\"] = scale\n",
    "        if logger is not None:\n",
    "            with open(logger, \"a+\") as f:\n",
    "                f.write(json.dumps(scp_log_dict) + \"\\n\")\n",
    "        if save_img_dir is not None:\n",
    "            image_save = results[\"img\"]\n",
    "            save_name = \"{}_{}_{}\".format(\n",
    "                comm.get_rank(),\n",
    "                results_origin[\"image_id\"],\n",
    "                results_origin[\"mix_results\"][0][\"image_id\"],\n",
    "            )\n",
    "            cv2.imwrite(\n",
    "                os.path.join(save_img_dir, \"{}.jpg\".format(save_name)),\n",
    "                image_save.transpose(1, 2, 0)[..., ::-1],\n",
    "            )\n",
    "            with open(\n",
    "                os.path.join(save_img_dir, \"{}.json\".format(save_name)), \"w\"\n",
    "            ) as f:\n",
    "                f.write(json.dumps(scp_log_dict))\n",
    "            new_image_id = (\n",
    "                results_origin[\"image_id\"] * 100000000000\n",
    "                + results_origin[\"mix_results\"][0][\"image_id\"]\n",
    "            )\n",
    "        h, w = results[\"img\"].shape[-2:]\n",
    "        results_origin[\"image\"] = torch.from_numpy(results[\"img\"])\n",
    "        results_origin.pop(\"mix_results\")\n",
    "        results_origin[\"instances\"] = Instances((h, w))\n",
    "        results_origin[\"instances\"].gt_boxes = Boxes(results[\"gt_bboxes\"])\n",
    "        results_origin[\"instances\"].gt_classes = torch.tensor(\n",
    "            results[\"gt_labels\"], dtype=torch.int64\n",
    "        )\n",
    "        results_origin[\"instances\"].gt_masks = BitMasks(results[\"gt_masks\"])\n",
    "        results_origin[\"height\"], results_origin[\"width\"] = h, w\n",
    "        if save_img_dir is not None:\n",
    "\n",
    "            insta_save = copy.deepcopy(results_origin[\"instances\"])\n",
    "            insta_save.gt_classes += 1  # convert 0-index to 1-index\n",
    "\n",
    "            boxes = insta_save.gt_boxes.tensor.numpy()\n",
    "            boxes = BoxMode.convert(boxes, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n",
    "            boxes = boxes.tolist()\n",
    "            classes = insta_save.gt_classes.tolist()\n",
    "            results = []\n",
    "            for k in range(len(insta_save)):\n",
    "                result = {\n",
    "                    \"image_id\": new_image_id,\n",
    "                    \"category_id\": classes[k],\n",
    "                    \"bbox\": boxes[k],\n",
    "                    \"file_name\": \"{}.jpg\".format(save_name),\n",
    "                }\n",
    "                results.append(result)\n",
    "            # results = dict(annotations=results``)\n",
    "            with open(\n",
    "                os.path.join(save_img_dir, \"{}_gt.json\".format(save_name)), \"w\"\n",
    "            ) as f:\n",
    "                json.dump(results, f)\n",
    "\n",
    "        return results_origin\n",
    "\n",
    "    def _scp_src_to_dst(\n",
    "        self, dst_results, src_results, ret_valid_idx=False, is_tmp_dst=False\n",
    "    ):\n",
    "        if is_tmp_dst:\n",
    "            h1, w1 = (\n",
    "                dst_results[\"gt_bboxes\"][..., 3].max(),\n",
    "                dst_results[\"gt_bboxes\"][..., 2].max(),\n",
    "            )\n",
    "            h1, w1 = math.ceil(h1), math.ceil(w1)\n",
    "        else:\n",
    "            h1, w1 = dst_results[\"img\"].shape[-2:]\n",
    "        # TODO : whether thrunk the hw\n",
    "        # h2, w2 = selected_results['img'].shape[-2:]\n",
    "        h2, w2 = (\n",
    "            src_results[\"gt_bboxes\"][..., 3].max(),\n",
    "            src_results[\"gt_bboxes\"][..., 2].max(),\n",
    "        )\n",
    "        h2, w2 = math.ceil(h2), math.ceil(w2)\n",
    "        h, w = max(h1, h2), max(w1, w2)\n",
    "\n",
    "        scale = 1\n",
    "        if not is_tmp_dst and self.blank_ratio > 0:\n",
    "            composed_mask = np.where(np.any(src_results[\"gt_masks\"], axis=0), 1, 0)\n",
    "            ratio = (h2 * w2 - composed_mask.sum() - h1 * w1) / (h * w)\n",
    "            if ratio > self.blank_ratio:\n",
    "                h2_new = np.random.randint(int(0.5 * h1), int(1.1 * h1))\n",
    "                w2_new = np.random.randint(int(0.5 * w1), int(1.1 * w1))\n",
    "\n",
    "                scale = min(h2_new / h2, w2_new / w2)\n",
    "                new_hw = [int(x * scale) for x in src_results[\"img\"].shape[-2:]]\n",
    "\n",
    "                def resize(x, size):\n",
    "                    wh_size = size[::-1]\n",
    "                    result = cv2.resize(x.transpose(1, 2, 0), wh_size)\n",
    "                    if len(result.shape) == 2:\n",
    "                        result = result[..., None]\n",
    "                    return result.transpose(2, 0, 1)\n",
    "\n",
    "                src_results[\"img\"] = resize(src_results[\"img\"], new_hw)\n",
    "                if len(src_results[\"gt_masks\"]):\n",
    "                    src_results[\"gt_masks\"] = resize(\n",
    "                        src_results[\"gt_masks\"].astype(src_results[\"img\"].dtype), new_hw\n",
    "                    ).astype(bool)\n",
    "                src_results[\"gt_bboxes\"] = src_results[\"gt_bboxes\"] * scale\n",
    "                h2, w2 = h2_new, w2_new\n",
    "                h, w = max(h1, h2), max(w1, w2)\n",
    "\n",
    "        def pad_to_hw(data, h, w):\n",
    "            new_data = np.zeros((data.shape[0], h, w), dtype=data.dtype)\n",
    "            d_h, d_w = min(h, data.shape[1]), min(w, data.shape[2])\n",
    "            new_data[:, :d_h, :d_w] = data[:, :d_h, :d_w]\n",
    "            # new_data[:,:data.shape[1],:data.shape[2]] = data\n",
    "            return new_data\n",
    "\n",
    "        for k in [\"img\", \"gt_masks\"]:\n",
    "            dst_results[k] = pad_to_hw(dst_results[k], h, w)\n",
    "            src_results[k] = pad_to_hw(src_results[k], h, w)\n",
    "        if ret_valid_idx:\n",
    "            results, valid_idx = self._copy_paste(\n",
    "                dst_results, src_results, ret_valid_idx\n",
    "            )\n",
    "            return results, valid_idx, scale\n",
    "        return self._copy_paste(dst_results, src_results, ret_valid_idx)\n",
    "        # results, valid_idx = self._copy_paste(dst_results, src_results)\n",
    "        # return results\n",
    "\n",
    "    def _select_object(self, results):\n",
    "        \"\"\"Select some objects from the source results.\"\"\"\n",
    "        bboxes = results[\"gt_bboxes\"]\n",
    "        labels = results[\"gt_labels\"]\n",
    "        masks = results[\"gt_masks\"]\n",
    "        max_num_pasted = min(bboxes.shape[0] + 1, self.max_num_pasted)\n",
    "        # print('num paste', max_num_pasted)\n",
    "        num_pasted = np.random.randint(0, max_num_pasted)\n",
    "        selected_inds = np.random.choice(\n",
    "            bboxes.shape[0], size=num_pasted, replace=False\n",
    "        )\n",
    "\n",
    "        selected_bboxes = bboxes[selected_inds]\n",
    "        selected_labels = labels[selected_inds]\n",
    "        selected_masks = masks[selected_inds]\n",
    "\n",
    "        results[\"gt_bboxes\"] = selected_bboxes\n",
    "        results[\"gt_labels\"] = selected_labels\n",
    "        results[\"gt_masks\"] = selected_masks\n",
    "        return results\n",
    "\n",
    "    def get_bboxes(self, masks):\n",
    "        num_masks = len(masks)\n",
    "        boxes = np.zeros((num_masks, 4), dtype=np.float32)\n",
    "        x_any = masks.any(axis=1)\n",
    "        y_any = masks.any(axis=2)\n",
    "        for idx in range(num_masks):\n",
    "            x = np.where(x_any[idx, :])[0]\n",
    "            y = np.where(y_any[idx, :])[0]\n",
    "            if len(x) > 0 and len(y) > 0:\n",
    "                # use +1 for x_max and y_max so that the right and bottom\n",
    "                # boundary of instance masks are fully included by the box\n",
    "                boxes[idx, :] = np.array(\n",
    "                    [x[0], y[0], x[-1] + 1, y[-1] + 1], dtype=np.float32\n",
    "                )\n",
    "        return boxes\n",
    "\n",
    "    def _copy_paste(self, dst_results, src_results, ret_valid_idx=False):\n",
    "        \"\"\"CopyPaste transform function.\n",
    "        Args:\n",
    "            dst_results (dict): Result dict of the destination image.\n",
    "            src_results (dict): Result dict of the source image.\n",
    "        Returns:\n",
    "            dict: Updated result dict.\n",
    "        \"\"\"\n",
    "        dst_img = dst_results[\"img\"]\n",
    "        dst_bboxes = dst_results[\"gt_bboxes\"]\n",
    "        dst_labels = dst_results[\"gt_labels\"]\n",
    "        dst_masks = dst_results[\"gt_masks\"]\n",
    "\n",
    "        src_img = src_results[\"img\"]\n",
    "        src_bboxes = src_results[\"gt_bboxes\"]\n",
    "        src_labels = src_results[\"gt_labels\"]\n",
    "        src_masks = src_results[\"gt_masks\"]\n",
    "\n",
    "        # print('src shape', src_bboxes.shape)\n",
    "        if len(src_bboxes) == 0:\n",
    "            return dst_results\n",
    "\n",
    "        # update masks and generate bboxes from updated masks\n",
    "        composed_mask = np.where(np.any(src_masks, axis=0), 1, 0)\n",
    "        updated_dst_masks = self.get_updated_masks(dst_masks, composed_mask)\n",
    "        # updated_dst_bboxes = updated_dst_masks.get_bboxes()\n",
    "        updated_dst_bboxes = self.get_bboxes(updated_dst_masks)\n",
    "        assert len(updated_dst_bboxes) == len(updated_dst_masks)\n",
    "\n",
    "        # filter totally occluded objects\n",
    "        bboxes_inds = np.all(\n",
    "            np.abs((updated_dst_bboxes - dst_bboxes)) <= self.bbox_occluded_thr, axis=-1\n",
    "        )\n",
    "        masks_inds = updated_dst_masks.sum(axis=(1, 2)) > self.mask_occluded_thr\n",
    "        valid_inds = bboxes_inds | masks_inds\n",
    "\n",
    "        # Paste source objects to destination image directly\n",
    "        img = blend_image(dst_img, src_img, composed_mask, self.cp_method).astype(\n",
    "            dst_img.dtype\n",
    "        )\n",
    "        # elif self.cp_method=='basic':\n",
    "        #     img = (dst_img * (1 - composed_mask\n",
    "        #                     ) + src_img * composed_mask).astype(dst_img.dtype)\n",
    "        # elif self.cp_method=='possion':\n",
    "        #     src_img=src_img.transpose(1,2,0)\n",
    "        #     dst_img=dst_img.transpose(1,2,0)\n",
    "        #     img=poisson_edit(src_img,dst_img,composed_mask)\n",
    "        #     img_base=(dst_img * (1 - composed_mask[:,:,None]) + src_img * composed_mask[:,:,None]).astype(dst_img.dtype)\n",
    "        #     import os\n",
    "        #     img_id=np.random.random_integers(0,999999)\n",
    "        #     os.makedirs('visualizations',exist_ok=True)\n",
    "        #     cv2.imwrite('visualizations/%06d_origin.png'%img_id,dst_img[:,:,::-1])\n",
    "        #     cv2.imwrite('visualizations/%06d_paste.png'%img_id,img_base[:,:,::-1])\n",
    "        #     cv2.imwrite('visualizations/%06d_possion.png'%img_id,img[:,:,::-1])\n",
    "        #     #img=cv2.seamlessClone(src_img.astype('uint8'), dst_img.astype('uint8') ,composed_mask.astype('uint8'), (src_img.shape[0]//2,src_img.shape[1]//2), cv2.MIXED_CLONE)\n",
    "        #     src_img=src_img.transpose(2,0,1)\n",
    "        #     dst_img=dst_img.transpose(2,0,1)\n",
    "        #     img=img.transpose(2,0,1)\n",
    "        bboxes = np.concatenate([updated_dst_bboxes[valid_inds], src_bboxes])\n",
    "        labels = np.concatenate([dst_labels[valid_inds], src_labels])\n",
    "        masks = np.concatenate([updated_dst_masks[valid_inds], src_masks])\n",
    "\n",
    "        dst_results[\"img\"] = img\n",
    "        dst_results[\"gt_bboxes\"] = bboxes\n",
    "        dst_results[\"gt_labels\"] = labels\n",
    "        dst_results[\"gt_masks\"] = masks\n",
    "        # dst_results['gt_masks'] = BitmapMasks(masks, masks.shape[1],\n",
    "        #   masks.shape[2])\n",
    "\n",
    "        if ret_valid_idx:\n",
    "            return dst_results, valid_inds\n",
    "        return dst_results\n",
    "\n",
    "    def get_updated_masks(self, masks, composed_mask):\n",
    "        assert (\n",
    "            masks.shape[-2:] == composed_mask.shape[-2:]\n",
    "        ), \"Cannot compare two arrays of different size {} {}\".format(\n",
    "            masks.shape, composed_mask.shape\n",
    "        )\n",
    "        masks = np.where(composed_mask, 0, masks)\n",
    "        return masks\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr_str = self.__class__.__name__\n",
    "        repr_str += f\"max_num_pasted={self.max_num_pasted}, \"\n",
    "        repr_str += f\"bbox_occluded_thr={self.bbox_occluded_thr}, \"\n",
    "        repr_str += f\"mask_occluded_thr={self.mask_occluded_thr}, \"\n",
    "        repr_str += f\"selected={self.selected}, \"\n",
    "        return repr_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copypaste import CopyPaste\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, DatasetMapper\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data.build import build_detection_train_loader\n",
    "from detectron2.data.transforms import (\n",
    "    RandomCrop,\n",
    "    RandomFlip,\n",
    "    RandomRotation,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    RandomSaturation,\n",
    "    RandomLighting,\n",
    ")\n",
    "import torch\n",
    "from detectron2.data.transforms import Augmentation, Transform\n",
    "\n",
    "\n",
    "class CopyPasteWrapper(Augmentation):\n",
    "    def __init__(self, copy_paste_augmentation):\n",
    "        self.copy_paste_augmentation = copy_paste_augmentation\n",
    "\n",
    "    def get_transform(self, image):\n",
    "        return self.copy_paste_augmentation\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.copy_paste_augmentation(image)\n",
    "\n",
    "\n",
    "# Instantiate your CopyPaste augmentation\n",
    "copy_paste_augmentation = CopyPaste()\n",
    "\n",
    "# Wrap CopyPaste augmentation\n",
    "copy_paste_wrapper = CopyPasteWrapper(copy_paste_augmentation)\n",
    "\n",
    "# Register COCO dataset\n",
    "register_coco_instances(\n",
    "    \"coco_val_20171\",\n",
    "    {},\n",
    "    \"../data/annotations/instances_val2017.json\",\n",
    "    \"../data/val2017\",\n",
    ")\n",
    "\n",
    "# Get dataset and metadata\n",
    "dataset_dicts = DatasetCatalog.get(\"coco_val_20171\")\n",
    "metadata = MetadataCatalog.get(\"coco_val_20171\")\n",
    "\n",
    "# Define data augmentation\n",
    "data_augmentation = [\n",
    "    RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
    "    RandomRotation(angle=[0, 360], expand=False, center=None, sample_style=\"range\"),\n",
    "    RandomBrightness(intensity_min=0.8, intensity_max=1.2),\n",
    "    RandomContrast(intensity_min=0.8, intensity_max=1.2),\n",
    "    RandomSaturation(intensity_min=0.8, intensity_max=1.2),\n",
    "    RandomLighting(scale=0.2),\n",
    "    RandomCrop(\"relative_range\", [0.8, 0.8]),\n",
    "    copy_paste_wrapper,\n",
    "]\n",
    "\n",
    "# Build dataloader\n",
    "dataloader = build_detection_train_loader(\n",
    "    dataset=dataset_dicts,\n",
    "    mapper=DatasetMapper(\n",
    "        is_train=True, augmentations=data_augmentation, image_format=\"BGR\"\n",
    "    ),\n",
    "    total_batch_size=8,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/erikriise/anaconda3/envs/DiffAug/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/erikriise/anaconda3/envs/DiffAug/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n    data.append(next(self.dataset_iter))\n  File \"/Users/erikriise/anaconda3/envs/DiffAug/lib/python3.9/site-packages/detectron2/data/common.py\", line 296, in __iter__\n    yield self.dataset[idx]\n  File \"/Users/erikriise/anaconda3/envs/DiffAug/lib/python3.9/site-packages/detectron2/data/common.py\", line 125, in __getitem__\n    data = self._map_func(self._dataset[cur_idx])\n  File \"/Users/erikriise/anaconda3/envs/DiffAug/lib/python3.9/site-packages/detectron2/data/dataset_mapper.py\", line 164, in __call__\n    transforms = self.augmentations(aug_input)\n  File \"/Users/erikriise/anaconda3/envs/DiffAug/lib/python3.9/site-packages/detectron2/data/transforms/augmentation.py\", line 267, in __call__\n    tfm = x(aug_input)\n  File \"/var/folders/6l/_d0k81l969n6zvw6fgpq650w0000gn/T/ipykernel_14007/2965115415.py\", line 13, in __call__\n  File \"/Users/erikriise/Documents/python_projects/ADLCV/copy_paste/copypaste.py\", line 250, in __call__\n    if 'inp_image' in results :\nTypeError: argument of type 'AugInput' is not iterable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get one batch of data\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      5\u001b[0m     images \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Convert BGR to RGB\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DiffAug/lib/python3.9/site-packages/detectron2/data/common.py:329\u001b[0m, in \u001b[0;36mAspectRatioGroupedDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 329\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset:\n\u001b[1;32m    330\u001b[0m         w, h \u001b[38;5;241m=\u001b[39m d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m], d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    331\u001b[0m         bucket_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;241m>\u001b[39m h \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/DiffAug/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/DiffAug/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DiffAug/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/DiffAug/lib/python3.9/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/erikriise/anaconda3/envs/DiffAug/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/erikriise/anaconda3/envs/DiffAug/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n    data.append(next(self.dataset_iter))\n  File \"/Users/erikriise/anaconda3/envs/DiffAug/lib/python3.9/site-packages/detectron2/data/common.py\", line 296, in __iter__\n    yield self.dataset[idx]\n  File \"/Users/erikriise/anaconda3/envs/DiffAug/lib/python3.9/site-packages/detectron2/data/common.py\", line 125, in __getitem__\n    data = self._map_func(self._dataset[cur_idx])\n  File \"/Users/erikriise/anaconda3/envs/DiffAug/lib/python3.9/site-packages/detectron2/data/dataset_mapper.py\", line 164, in __call__\n    transforms = self.augmentations(aug_input)\n  File \"/Users/erikriise/anaconda3/envs/DiffAug/lib/python3.9/site-packages/detectron2/data/transforms/augmentation.py\", line 267, in __call__\n    tfm = x(aug_input)\n  File \"/var/folders/6l/_d0k81l969n6zvw6fgpq650w0000gn/T/ipykernel_14007/2965115415.py\", line 13, in __call__\n  File \"/Users/erikriise/Documents/python_projects/ADLCV/copy_paste/copypaste.py\", line 250, in __call__\n    if 'inp_image' in results :\nTypeError: argument of type 'AugInput' is not iterable\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get one batch of data\n",
    "for batch in dataloader:\n",
    "    images = batch[\"image\"]\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    images = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in images]\n",
    "\n",
    "    # Apply transformations to the images\n",
    "    transformed_images = [copy_paste_augmentation(image=img)[\"image\"] for img in images]\n",
    "\n",
    "    # Visualize original and transformed images\n",
    "    num_images = len(images)\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(2, num_images, num_images + i + 1)\n",
    "        plt.imshow(transformed_images[i])\n",
    "        plt.title(\"Transformed\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Display only one batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DiffAug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
